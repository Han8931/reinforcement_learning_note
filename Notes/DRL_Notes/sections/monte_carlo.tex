\chapter{Monte Carlo Method}

\section{First Visit v.s., Every Visit}
The first-visit and the every-visit Monte-Carlo (MC) algorithms are both used to solve the prediction problem (or, also called, ``evaluation problem''), that is, the problem of estimating the \textbf{value function} associated with a given (as input to the algorithms) fixed (that is, it does not change during the execution of the algorithm) policy, denoted by $\pi$. In general, even if we are given the policy $\pi$, we are not necessarily able to find the exact corresponding value function, so these two algorithms are used to estimate the value function associated with $\pi$.

Intuitively, we care about the value function associated with $\pi$ because we might want or need to know ``how good it is to be in a certain state'', if the agent behaves in the environment according to the policy $\pi$.
